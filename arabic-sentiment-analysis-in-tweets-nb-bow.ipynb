{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arabic Sentiment Analysis in tweets using Naive Bayes Machine learning Algorithm and unigram features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_Arabic_tweets_negative_20190413.tsv\n",
      "test_Arabic_tweets_positive_20190413.tsv\n",
      "train_Arabic_tweets_negative_20190413.tsv\n",
      "train_Arabic_tweets_positive_20190413.tsv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import nltk\n",
    "from nltk import NaiveBayesClassifier\n",
    "from nltk.metrics.scores import f_measure, precision, recall\n",
    "import collections\n",
    "\n",
    "\n",
    "# Input data files are available in the \"input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "for filename in os.listdir(\"input\"):\n",
    "    print(filename)\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from itertools import islice\n",
    "\n",
    "def load_tsv(data_file, n):\n",
    "    data_features = list()\n",
    "    data = list()\n",
    "    infile = open(data_file, encoding='utf-8')\n",
    "    for line in infile:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        label, text = line.split('\\t')\n",
    "        text_features = process_text(text, n)\n",
    "        if text_features:\n",
    "            data_features += text_features\n",
    "            data.append((text_features, label))\n",
    "    return data, data_features\n",
    "\n",
    "def process_text(text, n=1,\n",
    "                 remove_vowel_marks=False,\n",
    "                 remove_repeated_chars=False,\n",
    "                 ):\n",
    "    clean_text = text\n",
    "    if remove_vowel_marks:\n",
    "        clean_text = remove_diacritics(clean_text)\n",
    "    if remove_repeated_chars:\n",
    "        clean_text = remove_repeating_char(clean_text)\n",
    "\n",
    "    if n == 1:\n",
    "        return clean_text.split()\n",
    "    else:\n",
    "        tokens = clean_text.split()\n",
    "        grams = tokens\n",
    "        for i in range(2, n + 1):\n",
    "            grams += [  ' '.join(g) for g in list(window(tokens, i))  ]\n",
    "        return grams\n",
    "\n",
    "\n",
    "\n",
    "def window(words_seq, n):\n",
    "    \"\"\"Returns a sliding window (of width n) over data from the iterable\"\"\"\n",
    "    \"   s -> (s0,s1,...s[n-1]), (s1,s2,...,sn), ...                   \"\n",
    "    it = iter(words_seq)\n",
    "    result = tuple(islice(it, n))\n",
    "    if len(result) == n:\n",
    "        yield result\n",
    "    for elem in it:\n",
    "        result = result[1:] + (elem,)\n",
    "        yield result\n",
    "\n",
    "\n",
    "def remove_repeating_char(text):\n",
    "    # return re.sub(r'(.)\\1+', r'\\1', text)     # keep only 1 repeat\n",
    "    return re.sub(r'(.)\\1+', r'\\1\\1', text)  # keep 2 repeat\n",
    "\n",
    "def document_features(document, corpus_features):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in corpus_features:\n",
    "        features['has({})'.format(word)] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data files\n",
      "train file (pos) input/train_Arabic_tweets_positive_20190413.tsv\n",
      "train file (neg) input/train_Arabic_tweets_negative_20190413.tsv\n",
      "test file (pos) input/test_Arabic_tweets_positive_20190413.tsv\n",
      "test file (neg) input/test_Arabic_tweets_negative_20190413.tsv\n"
     ]
    }
   ],
   "source": [
    "pos_train_file = 'input/train_Arabic_tweets_positive_20190413.tsv'\n",
    "neg_train_file = 'input/train_Arabic_tweets_negative_20190413.tsv'\n",
    "\n",
    "pos_test_file = 'input/test_Arabic_tweets_positive_20190413.tsv'\n",
    "neg_test_file = 'input/test_Arabic_tweets_negative_20190413.tsv'\n",
    "print('data files')\n",
    "print('train file (pos)', pos_train_file)\n",
    "print('train file (neg)', neg_train_file)\n",
    "print('test file (pos)', pos_test_file)\n",
    "print('test file (neg)', neg_test_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters (ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters\n",
      "n grams: 1\n"
     ]
    }
   ],
   "source": [
    "print('parameters')\n",
    "n = 1\n",
    "print('n grams:', n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading train data .... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train data ....\n",
      "loading test data ....\n"
     ]
    }
   ],
   "source": [
    "print('loading train data ....')\n",
    "pos_train_data, pos_train_feat = load_tsv(pos_train_file, n)\n",
    "neg_train_data, neg_train_feat = load_tsv(neg_train_file, n)\n",
    "print('loading test data ....')\n",
    "pos_test_data, pos_test_feat = load_tsv(pos_test_file, n)\n",
    "neg_test_data, neg_test_feat = load_tsv(neg_test_file, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training data information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data info\n",
      "train data size 47000\n",
      "# of positive 23879\n",
      "# of negative 23121\n"
     ]
    }
   ],
   "source": [
    "print('train data info')\n",
    "train_data = pos_train_data + neg_train_data\n",
    "print('train data size', len(train_data))\n",
    "print('# of positive', len(pos_train_data))\n",
    "print('# of negative', len(neg_train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample training data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 random tweets .... \n",
      "(['Ø·Ø¨ÙŠØ¹ÙŠ', 'ÙƒÙ„', 'Ø£Ø¬ÙˆØ¨Ø©', 'Ø§Ù…ØªØ­Ø§Ù†', 'Ø§Ù„Ø¹Ø±Ø¨ÙŠ', 'ØªØªØ´Ø§Ø¨Ù‡', 'Ø§ÙŠÙŠØ´Ø´', 'ÙÙŠÙŠÙ‡', 'ÙŠØ§', 'ÙˆØ§Ø¯', 'ğŸ˜‘'], 'neg')\n",
      "(['Ø¨Ø³', 'Ù‡Ùˆ', 'Ø·Ø¹Ù…Ù‡', 'Ø§Ø­Ù„ÙŠ', 'Ù…Ù†', 'Ø§Ø¨Ùˆ', 'Ø¬Ù†ÙŠÙ‡', 'ğŸ˜‚ğŸ˜‚ğŸ’–ğŸ’–'], 'pos')\n",
      "(['ØºÙŠÙ…Ù‡', 'Ù‡Ø§Ø¯Ø¦Ø©', 'ØªÙ…Ø·Ø±', 'ÙƒÙ„Ù…Ø§', 'Ø§Ø´ØªØ¯', 'Ø­Ø²Ù†Ùƒ', 'Ù„ØªØºØ³Ù„', 'Ø¹Ù†Ùƒ', 'Ø°Ù„Ùƒ', 'Ø§Ù„Ø­Ø²Ù†', 'ğŸ’“', '#ØµØ¨Ø§Ø­_Ø§Ù„Ø®ÙŠØ±'], 'pos')\n",
      "(['ØµØ¨Ø§Ø­', 'Ø§Ù„ÙˆØ±Ø¯', 'ğŸŒ·'], 'pos')\n",
      "(['Ø°Ø§', 'Ø§Ù„ÙƒÙØ§Ø±', 'Ù…Ø§', 'Ø¨Ù‚Ù‰', 'Ø´ÙŠØ¡', 'Ø§Ù„Ø§', 'Ø³ÙˆÙˆÙ‡', 'ğŸ˜'], 'neg')\n",
      "(['Ø£Ø¬Ù…Ù„', 'ØªØ¹Ø¨', 'ÙˆØ§Ù„Ù„Ù‡', 'ğŸ˜‚'], 'pos')\n",
      "(['Ù„Ùˆ', 'Ù…Ø®Ù„ÙŠÙ†Ù‡Ø§', 'Ø¨Ø§Ù„Ø¨ÙŠØª', 'Ø§Ø­Ø³Ù†', 'Ù„Ù‡Ø§', 'ÙŠÙˆÙ…Ù‡Ù…', 'Ø¨ÙŠØ®Ù„ÙˆÙ†Ù‡Ø§', 'Ø¨Ø±Ø§!', 'ÙÙŠÙ‡', 'Ù†Ø§Ø³', 'Ø¬Ø­Ù„Ø·', 'ÙˆØ±Ø¨ÙŠ', 'ÙˆØ¹Ø§ÙŠØ´ÙŠÙ†', 'Ø¹ÙŠØ´Ø©', 'Ø§Ù„Ø·Ø¨Ù‚ÙŠÙ‡', 'Ø¨Ø´ÙƒÙ„', 'ØºÙ„Ø·!!'], 'neg')\n",
      "(['Ø­ÙƒÙ…Ø©', 'Ø¨Ø¹Ø¯', 'Ø§Ù„Ø¹ØµØ±', ':', 'Ù…Ù‡Ù…Ø§', 'ÙƒØ§Ù†Øª', 'Ø§Ù„Ø§Ø¯Ù„Ø©', 'Ù‚ÙˆÙŠØ©', 'Ø§Ø¬Ø­Ø¯', 'ÙŠØ§', 'ÙˆØ­Ø´', 'ğŸ˜'], 'pos')\n",
      "(['Ø¹Ø´', 'Ù…Ø­Ø§Ø·Ø§', 'Ø¨ÙƒÙ„', 'Ø§Ù„Ø£Ø´ÙŠØ§Ø¡', 'Ø§Ù„Ù…Ù†Ø³ÙˆØ¨Ù‡', 'Ù„Ù„Ø±Ù‚Ù‡', 'ğŸŒ¸'], 'pos')\n",
      "(['Ø±Ø¨Ù…Ø§', 'Ø§Ù„Ø­ÙŠØ§Ø©', 'Ù„Ø§', 'ØªØ¹Ø·ÙŠÙ†Ø§', 'ÙƒÙ„', 'Ù…Ø§', 'Ù†Ø±ÙŠØ¯', 'Ù„ÙƒÙ†', 'Ø§Ù„Ù‚Ù†Ø§Ø¹Ø©', 'ØªØ¹Ø·ÙŠÙ†Ø§', 'ÙƒÙ„', 'Ø§Ù„Ø­ÙŠØ§Ø©', 'ğŸŒ¸'], 'pos')\n",
      "(['â €', 'â €', 'â €', 'â €', 'â €', 'Ø¥Ø°Ø§', 'Ø¹Ø«Ø±Øª', 'Ø¹Ù„Ù‰', 'Ø´Ø®Øµ', 'ÙŠØªÙ‚Ø¨Ù„', 'Ø§ÙÙƒØ§Ø±Ùƒ', 'Ø§Ù„ØºØ±ÙŠØ¨Ø©', 'ØŒ', 'Ø³ÙˆÙ', 'ÙŠÙƒÙˆÙ†', 'Ø¨Ù…Ø«Ø§Ø¨Ø©', 'ÙƒÙ†Ø²', 'ÙˆÙ„ÙŠØ³', 'Ø´Ø®Øµ', 'ÙÙ‚Ø·', 'ğŸ’', 'â €', 'â €', 'â €', 'â €', 'â €', 'â €'], 'pos')\n",
      "(['Ø§Ù„Ù„Ù‡Ù…', 'Ø±Ø¨', 'Ø§Ù„Ù†Ø§Ø³', 'Ø£Ø°Ù‡Ø¨', 'Ø§Ù„Ø¨Ø§Ø³', 'ÙˆØ¢Ø´Ù', 'Ø£Ù†Øª', 'Ø§Ù„Ø´Ø§ÙÙŠ', 'Ù„Ø§', 'Ø´ÙØ§Ø¡', 'Ø¥Ù„Ø§', 'Ø´ÙØ§Ø¤Ùƒ', '..', 'Ø´ÙØ§Ø¡', 'Ù„Ø§', 'ÙŠØºØ§Ø¯Ø±', 'Ø³Ù‚Ù…Ø§', '..', 'Ø§Ù„Ù„Ù‡Ù…', 'Ø§Ø´Ù', '#ÙˆÙ„Ø¯ÙŠ_Ø°ÙŠØ§Ø¨', 'Ø§Ù„Ù„Ù‡Ù…â€¦'], 'neg')\n",
      "(['Ù‡Ù…Ø§', 'Ø¨ÙŠÙˆØ­Ø´ÙˆÙ†Ø§', 'Ø§ÙˆÙˆÙŠ', 'Ø¨Ø³', 'Ù…ÙŠÙ†ÙØ¹Ø´', 'Ù†ØªÙƒÙ„Ù…..!!', 'ğŸ’”'], 'neg')\n",
      "(['â€¢', 'ÙÙˆØ§Ø¦Ø¯', '#Ø§Ù„ØªØ¨Ø±Ø¹', 'Ø¨Ø§Ù„Ø¯Ù…', 'ğŸ’‰', '..', 'â€¢', '#ØµØ­Ø©'], 'neg')\n",
      "(['Ù…Ø§', 'Ø§ØªÙˆÙ‚Ø¹', 'Ù‡Ø°Ø§', 'Ø¨ÙŠØµÙŠØ±', 'ğŸ¤”'], 'neg')\n",
      "(['â™¡', '~', '~', '~', 'Ù„Ø§', 'ØªÙÙ‚Ø¯', 'Ù…Ø§', 'Ø£Ù…ØªÙ„ÙƒØªÙ‡', 'ÙŠÙˆÙ…Ø§', 'Ø­ØªÙ‰', 'Ù„Ùˆ', 'ÙƒØ§Ù†', 'Ø°ÙƒØ±Ù‰', 'Ø·ÙŠØ¨Ø©', 'ÙÙ„ÙŠØ³', 'ÙƒÙ„', 'Ù‚Ø±ÙŠØ¨', 'ÙŠÙ†Ø§Ù„', 'ÙˆÙ„Ø§', 'ÙƒÙ„', 'Ø¨Ø¹ÙŠØ¯', 'ÙŠÙ†Ø³Ù‰'], 'pos')\n",
      "(['ØªØµØ¯Ù‚', 'ØµØ­', 'ğŸ¤”'], 'neg')\n",
      "(['ØµØ¯Ù‚Øª', 'Ø§Ù„ÙŠØ³Ø§', 'Ø­ÙŠÙ†', 'ØºÙ†Øª', '\"Ù…Ø´', 'ÙƒÙ„', 'Ø§Ù„Ù„ÙŠ', 'Ø¨Ù†Ø­Ø¨Ù‡Ù…', 'Ù‡ÙŠÙƒÙˆÙ†ÙˆØ§', 'Ù„ÙŠÙ†Ø§', '\"', 'ğŸ’”'], 'neg')\n",
      "(['Ø£Ø«Ø¨ØªØª', 'Ø§Ù„Ø¢Ø¨Ø­Ø§Ø«', 'ÙˆØ£Ø«Ø¨Øª', 'Ø§Ù„Ø¹Ù„Ù…Ø§Ø¡', '..!!:ØŸ', '.', '.', 'ïºƒï»¥', 'Ø§Ø³ØªØ®Ø¯Ø§Ù…', 'Ø§Ù„ØªÙˆÙŠØªØ±', 'Ø¯ÙˆÙ†', 'Ø²ÙŠØ§Ø±Ø©', 'ØµÙØ­ØªÙŠ', 'Ù‚Ø¯', 'ÙŠØ¤Ø¯ÙŠ', 'Ø¨Ùƒ', 'Ø§Ù„Ù‰', 'ÙÙ‚Ø¯Ø¢Ù†', 'Ø§Ù„Ø³Ø¹Ø¢Ø¯Ù‡â€¦'], 'neg')\n",
      "(['â€¢Ø§Ø¨Ø¯Ø¦ÙŠ', 'Ø¨Ø¢ÙŠØ§Øª', 'Ù…Ù†', 'Ø§Ù„Ù‚Ø±Ø¢Ù†', 'Ù‚Ø¨Ù„', 'Ø¯Ø®ÙˆÙ„', 'ÙÙŠ', 'Ø¬Ùˆ', 'Ø§Ù„Ù…Ø°Ø§ÙƒØ±Ù‡', 'Ù„Ø§Ù†', 'Ø±Ø§Ø­', 'ØªØ­Ø³ÙŠÙ†', 'Ø¨Ø·Ù…Ø£Ù†ÙŠÙ†Ø©', 'ÙˆØªÙŠØ³ÙŠØ±', 'Ø¹Ø¬ÙŠØ¨â˜ï¸', 'â€¢', 'Ø­Ø§ÙˆÙ„ÙŠ', 'ØªØºØ±Ø³ÙŠÙ†', 'ÙÙŠ', 'Ø¨Ø§Ù„Ùƒ', 'Ø§Ù†', 'Ø§Ù„Ù„ÙŠâ€¦'], 'pos')\n",
      "(['ğŸš¨', 'Ø§Ù„Ù†ØµØ±', 'Ø§Ø±Ø³Ù„', 'Ø®Ø·Ø§Ø¨', 'Ù„Ø§ØªØ­Ø§Ø¯', 'Ø§Ù„Ù‚Ø¯Ù…', 'ÙŠÙÙŠØ¯', 'Ø¨Ø§Ø³ØªØ¨Ø¹Ø§Ø¯', 'Ø­ÙƒØ§Ù…', 'Ù„Ø§', 'ÙŠÙ‚ÙˆØ¯ÙˆÙ†', 'Ø§ÙŠ', 'Ù„Ù‚Ø§Ø¡', 'Ù„Ù„ÙØ±ÙŠÙ‚', 'ÙÙŠ', 'Ø§Ù„Ø¬ÙˆÙ„Ø§Øª', 'Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©.', '(', 'Ø§Ù„Ø¬Ø²ÙŠØ±Ø©', ')'], 'pos')\n",
      "(['Ø¹Ø·Ø´Ø§Ù†', 'ÙŠØ§', 'Ø¨Ø±Ù‚', 'Ø§Ù„Ø³Ù…Ø§', 'ğŸ’”', 'Ø¨Ù…ÙˆØª', 'Ù…Ù†', 'Ø·ÙˆÙ„', 'Ø§Ù„ØºÙŠØ§Ø¨', 'Ø¨Ù…ÙˆØª', 'Ù…Ù†', 'ÙƒØ«Ø±', 'Ø§Ù„Ø¸Ù…Ø§', 'ÙˆØ§Ù†Øª', 'Ø¹Ù„Ù‰', 'Ù…ØªÙ†', 'Ø§Ù„Ø³Ø­Ø§Ø¨â¤ï¸Jâ¤ï¸'], 'neg')\n",
      "(['Ø­Ø³Ø§ÙÙ‡', 'Ù…Ø§ØªÙˆÙ‚Ø¹ØªÙ‡', 'Ø¨ÙŠÙ„Ø¹Ø¨', 'ÙÙŠÙ‡Ø§', 'ØŒ', 'Ø§Ù„Ù„Ù‡', 'ÙŠØ³Ø§Ù…Ø­Ùƒ', 'ÙŠØ§Ù…Ø­Ù…Ø¯', 'ğŸ’”'], 'neg')\n",
      "(['Ø¯Ø§Ø¦Ù…Ø§', 'Ø¨ÙƒÙ„', 'Ø§Ù„Ø¨Ù„Ø¯Ø§Ù†', 'Ø¯ÙˆØ±', 'Ø§Ù„Ø§Ø®ÙˆÙ†Ø¬ÙŠØ©', '-ÙŠØ®ØªØ§Ø±ÙˆÙ†', 'Ø£Ø­Ø¯', 'Ø§ØªØ¨Ø§Ø¹Ù‡Ù…', 'ÙˆÙŠØ¬Ø¹Ù„ÙˆÙ†Ù‡', 'Ø±Ù…Ø²', 'Ù„Ù„Ø«ÙˆØ±Ø©', 'Ø¨Ø§Ù„Ø¯Ø¹Ù…', 'Ø§Ù„Ø¥Ø¹Ù„Ø§Ù…ÙŠ', '-ÙŠØ¶Ø¹ÙˆÙ†', 'Ù‚Ù†Ø§ØµØ©', 'ÙˆÙŠØ³ØªÙ‡Ø¯ÙÙˆÙ†â€¦'], 'neg')\n",
      "(['4.19', '||', 'Ù…Ù‚Ø§Ù„', 'ğŸ“„', 'ØªØ­Ø¯Ø«Øª', 'ÙˆØ³Ø§Ø¦Ù„', 'Ø§Ù„Ø¥Ø¹Ù„Ø§Ù…', 'Ø§Ù„ÙƒÙˆØ±ÙŠ', 'Ø¹Ù†', 'ÙˆØµÙˆÙ„', 'Ø§Ù„Ø¨ÙˆÙ…', 'Ø¨Ø§Ù†Ù‚ØªØ§Ù†', 'Map', 'of', 'the', 'Soul:', 'Persona', 'Ù„Ù„Ù…Ø±ÙƒØ²', 'Ø§Ù„Ø£ÙˆÙ„', 'ÙÙŠ', 'Ù…Ø®Ø·Ø·â€¦'], 'pos')\n",
      "(['Ø­ÙŠÙŠÙ†Ø§', 'Ø§Ù„ÙƒÙˆØ²', 'Ø¬Ø±Ø§', 'ÙˆØ§Ø·ÙŠ', 'ğŸ˜‚'], 'pos')\n",
      "(['Ù‚Ø¯Ø±Ùˆ', 'Ù‚Ù„ÙˆØ¨', 'Ø§Ù„Ù‚ÙˆØ§Ø±ÙŠØ±', 'ğŸ¤—'], 'pos')\n",
      "(['Ù„Ø¹Ù„', 'Ø§Ù„Ù„Ù‡', 'Ø£Ø®Ø±', 'Ø¹Ù†Ùƒ', 'Ù…Ø§', 'ØªØªÙ…Ù†Ù‰', 'Ù„Ø£Ù†Ù‡', 'Ø£Ø±Ø§Ø¯', 'Ø£Ù†', 'ÙŠØ£ØªÙŠÙƒ', 'Ø£Ø¬Ù…Ù„', 'Ù…Ù…Ø§', 'ØªØªØ®ÙŠÙ„', 'Ø¥Ø·Ù…Ø¦Ù†', '#ØµØ¨Ø§Ø­_Ø§Ù„Ø®ÙŠØ±', 'ğŸŒ¸'], 'pos')\n",
      "(['Ø­ØªÙ‰', 'Ø§Ù†Ø§', 'ÙˆØ§Ù„Ù„Ù‡', 'ÙƒØ§Ù†', 'Ù„Ø°ÙŠØ°', 'ğŸ˜‹'], 'pos')\n",
      "(['ÙŠÙ…ÙƒÙ†', 'Ø¬ÙŠÙ„', 'Ø§Ù„ØªØ³Ø¹ÙŠÙ†Ø§Øª', 'ØªÙ„Ù‚Ù‰', 'Ø¶Ø±Ø¨Ø§Øª', 'Ø§Ù„Ø«Ù„Ø§Ø«ÙŠÙ†', 'Ù…Ø³Ø¨Ù‚Ø§', 'ÙØ¨Ø·Ù…Ù†Ùƒ', 'Ø±Ø­', 'Ù†ÙˆØµÙ„Ù‡', 'ÙˆØ§Ø­Ù†Ø§', 'Ù…Ù†ØªÙˆÙ‚Ø¹', 'Ø¶Ø±Ø¨Ø§Øª', 'Ø£Ù‚ÙˆÙ‰', 'ğŸ˜…'], 'pos')\n",
      "(['â €', 'â €', 'â €', 'â €', 'â €', 'â €', 'â €', 'â €', 'â €', 'Ù„Ø§', 'ØªÙ„ÙˆÙ…', 'Ø§Ù„Ø®Ø§ÙÙ‚', 'Ø§Ù†', 'Ø¹Ø´Ù‚', 'ØµÙˆØªÚ¯', 'ÙÙŠÙ‡', 'Ø¨Ø­Ø©', 'ØªØ¬ÙŠØ¨', 'Ø§Ù„ÙˆÙŠÙ„', 'ÙˆØ§Ù„Ø¹Ø§ÙÙŠÙ‡â¤ï¸', '#Ù†Ø¨Ø¶_Ø¹Ø§Ø´Ù‚', 'ğŸ’•'], 'pos')\n",
      "(['#Ø§Ù„Ø§Ù‡Ù„ÙŠ_Ø§Ù„Ù‡Ù„Ø§Ù„', 'Ø§ÙƒØªØ¨', 'ØªÙˆÙ‚Ø¹Ùƒ', 'Ù„Ù†ØªÙŠØ¬Ø©', 'Ù„Ù‚Ø§Ø¡', 'Ø§Ù„Ù‡Ù„Ø§Ù„', 'ÙˆØ§Ù„Ø§Ù‡Ù„ÙŠ', 'ØªØ­Øª', 'Ø§Ù„ØªØ§Ù‚', 'ğŸ‘‡', '#ØªØ­Ø¯ÙŠ_Ø§Ø³Ø±Ø¹_Ø±ÙˆÙ‚Ø§Ù†', 'ÙˆØ§Ø¯Ø®Ù„', 'ÙÙŠ', 'Ø³Ø­Ø¨', 'Ù‚ÙŠÙ…Ø©', 'Ø§ÙŠÙÙˆÙ†', 'X', 'Ø¹Ù„Ù‰â€¦'], 'neg')\n",
      "(['ÙŠÙƒÙÙŠÙ†ÙŠ', 'Ø§Ù†Ú¯', 'ØªØ±Ø§Ù‚Ø¨Ù†ÙŠ..ÙˆÙŠÙƒÙÙŠÙ†ÙŠ', 'Ø£Ù†Ù†ÙŠ', 'Ø£Ø´ØªØª', 'Ù†Ø¨Ø¶Ú¯', '..ÙˆØ£Ø³Ø±Ù‚', 'ÙˆÙ‚ØªÚ¯', 'ÙˆØ£ØªØ¹Ø¨', 'ØªÙÙƒÙŠØ±Ùƒ', '..', 'ğŸ’”', '!!'], 'neg')\n",
      "(['ğŸ’', 'ğŸ’”', 'Ù„Ø§', 'Ø§Ù„Ø¯Ø±Ø¨', 'Ø¯Ø±Ø¨ÙŠ', 'ÙˆÙ„Ø§', 'Ø§Ù„Ø¹Ù†ÙˆØ§Ù†', 'Ø¹Ù†ÙˆØ§Ù†ÙŠ', 'ÙˆÙ„Ø§', 'Ø§Ù„Ø¨Ù„Ø§Ø¯', 'ÙˆÙ„Ø§', 'Ø§Ù„Ø£ÙˆØ·Ø§Ù†', 'Ø£ÙˆØ·Ø§Ù†ÙŠ', 'Ø£Ù†Ø§', 'Ø§Ù„Ù…ØºÙŠØ¨Ø©', 'ÙÙŠ', 'Ø¬Ø¨', 'Ø§Ù„Ø²Ù…Ø§Ù†', 'Ø£Ù†Ø§', 'Ø±Ø¬Ø¹', 'Ø§Ù„ØµØ¯â€¦'], 'neg')\n",
      "(['Ø¥Ù†Øª', 'ØºÙŠÙŠØ±', 'ğŸ˜­', 'Ø¥Ù†Øª', 'Ù…Ø«Ù„', 'Ø§Ø®ØªÙŠÙŠ', 'Ø£Ø·Ù„Ø¹', 'Ø¹Ù„ÙŠÙƒ', 'Ø§Ù„ÙŠ', 'Ù…Ø§', 'Ø£Ø·Ù„Ø¹Ù‡', 'Ø¹Ù„Ù‰', 'Ø£Ø­Ø¯'], 'neg')\n",
      "(['Ø§Ù„Ø´ÙŠØ¡', 'Ø§Ù„ÙˆØ­ÙŠØ¯', 'Ø§Ù„Ø°ÙŠ', 'ÙˆØµÙ„ÙˆØ§', 'ÙÙŠÙ‡', 'Ù„Ù„Ø¹Ø§Ù„Ù…ÙŠØ©', 'Ù‡Ùˆ', ':', 'Ø§Ù„Ù…Ø³ÙŠØ§Ø±', '..!', '.', 'ØªØ±Ù‰', 'ÙƒØ§Ù†ÙˆØ§', 'ÙŠØ´Ø¬Ø¹ÙˆÙ†', 'Ø±ÙŠØ§Ù„', 'Ù…Ø¯Ø±ÙŠØ¯', 'Ø¶Ø¯', 'Ø§Ù„Ù†ØµØ±', 'ğŸ¤£'], 'pos')\n",
      "(['Ù…Ø¨Ø±ÙˆÙƒ', 'Ù„Ø¬Ù…ÙŠØ¹', 'Ø§Ù„Ø£Ø¨Ø·Ø§Ù„', 'Ø§Ù„ÙØ§Ø¦Ø²ÙŠÙ†', 'Ù…Ù†', 'ÙØ±ÙŠÙ‚', 'Ø¯Ø±Ø§Ø¬', 'ØŒØŒ', 'ÙˆÙŠØ³ØªØ§Ù‡Ù„ÙˆÙ†', 'ğŸ’'], 'pos')\n",
      "(['ÙÙŠ', 'Ø§Ù‚Ø§Ù„ÙŠÙ…', 'Ø§Ù„Ø¨Ù†ØºØ§Ù„', 'Ø§Ù„Ø²ÙˆØ¬Ù‡', 'Ø§Ù„ØªÙŠ', 'Ù„Ø§', 'ØªØ³Ù…Ø¹', 'ÙƒÙ„Ø§Ù…', 'Ø²ÙˆØ¬Ù‡Ø§', 'ÙŠÙ‚ÙˆÙ…ÙˆÙ†', 'Ø¨Ø­Ù„Ø§Ù‚Ø©', 'Ø´Ø¹Ø±Ù‡Ø§', 'ÙˆØªØ¨Ù‚Ù‰', 'ÙÙŠ', 'Ø¨ÙŠØª', 'Ø§Ù‡Ù„Ù‡Ø§', 'Ø­ØªØ¦', 'ÙŠØ¸Ù‡Ø±', 'Ø´Ø¹Ø±Ù‡Ø§', 'ÙˆØ¨Ø¹Ø¯', 'Ø«Ù„Ø§â€¦'], 'neg')\n",
      "(['ÙŠØ§Ø´ÙŠÙ†', 'Ø§Ù„ØªØ¹Ø¨', 'Ø§Ù„Ù„ÙŠ', 'ÙŠØµØ­ÙŠÙ†ÙŠ', 'Ù…Ùˆ', 'Ø§Ù„Ù†ÙˆÙ…', ':('], 'neg')\n",
      "(['Ø­Ø³Ø§Ø¨Ø§Øª', 'Ù…Ù„Ú¯ÙŠØ©â™›', 'ğŸŒŸğŸŒŸ', 'Ù…ØºØ±Ø¯ÙˆÙ†', 'Ù…Ù…ÙŠØ²ÙˆÙ†..', 'Ù„Ù‡Ù…', 'Ø­Ø¶ÙˆØ±', 'Ø£Ù†ÙŠÙ‚', 'ÙˆØ­Ø±ÙˆÙ', 'Ø±Ø¢Ù‚ÙŠØ©', 'ğŸŒ¸', '#Ø­Ø³Ø§Ø¨Ø§Øª_Ù…Ù„ÙƒÙŠØ©_ØªØ³ØªØ­Ù‚_Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø©', 'ğŸ‘‡ğŸ»ğŸ‘‡ğŸ»ğŸ‘‡ğŸ»ğŸ‘‡ğŸ»â€¦'], 'pos')\n",
      "(['ğŸ“Œ', 'Ù…ÙˆØ§Ù‚ÙŠØª', 'Ø§Ù„ØµÙ„Ø§Ø©', 'ğŸ•Œ:', 'ğŸ“Ù…Ø¯ÙŠÙ†Ø©', '#Ø§Ù„Ø±ÙŠØ§Ø¶', 'ğŸ“†', 'Ø§Ù„Ø³Ø¨Øª', 'Ø´Ø¹Ø¨Ø§Ù†', 'Ù‡', 'Ø£Ø¨Ø±ÙŠÙ„', 'Ù…', 'Ø§Ù„ÙØ¬Ø±', ':13', 'Øµ', 'Ø§Ù„Ø´Ø±ÙˆÙ‚', ':35', 'Øµ', 'Ø§Ù„Ø¸Ù‡Ø±', ':â€¦'], 'neg')\n",
      "(['Ù‚ÙˆØªÙ†Ø§', 'Ø¨Ø¹Ø¯', 'Ø§Ù„Ù„Ù‡', 'Ø¯Ø§Ø¦Ù…Ø§', 'Ø£Ù†ØªÙ…ğŸŒ¹ğŸ’™', 'Ø§Ù„Ù', 'Ù…Ø¨Ø±ÙˆÙˆÙƒ', 'ğŸ’™', 'Ø§Ù„Ø­Ù…Ø¯', 'Ù„Ù„Ù‡', 'Ùˆ', 'Ø§Ù„Ø´ÙƒØ±', 'Ù„Ù‡', 'ğŸ™'], 'pos')\n",
      "(['ÙŠØ§', 'ØµØ¨Ø±', 'Ù‚Ù„', 'Ù„ÙŠ', 'Ù‡Ù„', 'Ø£Ù†Ø§', 'Ø£ÙŠÙˆØ¨', 'ğŸ’”', 'Ø£Ù…', 'Ø£Ù†Ù†ÙŠ', 'ÙÙŠ', 'Ù„ÙˆØ¹ØªÙŠ', 'ÙŠØ¹Ù‚ÙˆØ¨ğŸ’”', 'Ø£ÙÙ†ÙŠØª', 'Ø¯Ù‡Ø±Ø§', 'ÙÙŠ', 'Ø§Ù†ØªØ¸Ø§Ø±', 'Ø£Ø­Ø¨ØªÙŠğŸ’”', 'ÙÙ…ØªÙ‰', 'Ø§Ù„Ø­Ø¨ÙŠØ¨', 'Ø¥Ù„Ù‰', 'Ø§Ù„Ø­Ø¨ÙŠØ¨', 'ÙŠØ¤Ùˆâ€¦'], 'neg')\n",
      "(['Ù‚Ù…Ø©', 'Ø§Ù„Ø§Ø­Ø¨Ø§Ø·', 'ÙŠÙˆÙ…', 'ØªØ­Ø³Ø¨', 'Ø§Ù†', 'Ø­Ù„Ù‚Ø©', 'Ø§Ù„Ø«Ø±ÙˆÙ†Ø²', 'Ø§Ù„ÙŠÙˆÙ…', 'Ø§Ù„Ù„ÙŠÙ„', 'ÙˆØªØ·Ù„Ø¹', 'ÙØ¬Ø±', 'Ø§Ù„Ø§Ø«Ù†ÙŠÙ†', 'Ù…Ø§Ø¹Ù„ÙŠÙƒÙ…', 'Ù…Ù†', 'Ø¹Ù‰Ø¯', 'Ø§Ù„ÙƒÙˆØ±Ø©', 'Ù‡Ø°Ø§'], 'neg')\n",
      "(['Ù‚Ø§Ù„', 'Ø§Ù„Ù†Ø¨ÙŠ', 'ØµÙ„Ù‰', 'Ø§Ù„Ù„Ù‡', 'Ø¹Ù„ÙŠÙ‡', 'ÙˆØ³Ù„Ù…:', 'Ø£ÙˆÙ„Ù‰', 'Ø§Ù„Ù†Ø§Ø³', 'Ø¨ÙŠ', 'ÙŠÙˆÙ…', 'Ø§Ù„Ù‚ÙŠØ§Ù…Ø©', 'Ø£ÙƒØ«Ø±Ù‡Ù…', 'Ø¹Ù„ÙŠ', 'ØµÙ„Ø§Ø©', 'ğŸŒ¹', 'Ø§Ù„Ù„Ù‡Ù…', 'ØµÙ„', 'ÙˆØ³Ù„Ù…', 'Ø¹Ù„Ù‰', 'Ù†Ø¨ÙŠÙ†Ø§', 'Ù…Ø­Ù…Ø¯', 'ÙˆØ¹Ù„Ù‰', 'Ø¢Ù„â€¦'], 'pos')\n",
      "(['#Ø§Ø¹ØªØ¨Ø±Ù†ÙŠ_ÙÙŠ_Ø­ÙŠØ§ØªÙƒ', '#ØµØ¨Ø§Ø­_Ø§Ù„Ø®ÙŠØ±á… ', 'Ù†ÙˆØ±Ø§Ù„Ù„Ù‡', 'Ù‚Ù„ÙˆØ¨ÙƒÙ…', 'Ø¨Ø°ÙƒØ±Ù‡', 'ÙˆØ´ÙƒØ±Ù‡', 'ÙˆØ­Ø³Ù†', 'Ø¹Ø¨Ø§Ø¯ØªÙ‡.', 'ÙˆØ±Ø²Ù‚ÙƒÙ…', 'Ø­Ø¨Ù‡', 'ÙˆØ§Ø¹Ø§Ù†ÙƒÙ…', 'Ø¹Ù„Ù‰', 'Ø·Ø§Ø¹ØªÙ‡.', 'ÙˆØ§ÙƒØ±Ù…ÙƒÙ…', 'Ø¨Ø¬â€¦'], 'pos')\n",
      "(['Ù…Ø±Ø§Ù‡Ù‚Ù‡', 'Ø¬Ø³Ù…Ù‡Ø§', 'Ø­Ù„Ùˆ', ':', 'ÙƒØ¨Ù„Ø²', 'Ù…ÙƒÙˆØ©', 'Ø´ÙŠÙ…ÙŠÙ„', 'ÙƒØ³', 'Ø´Ø°ÙˆØ°', 'ğŸ˜¬', 'Ø¥Ø¨Ø±ÙŠÙ„', ':19:03', 'Ù…Ø³Ø§Ø¡'], 'neg')\n",
      "(['Ù‡Ù‡Ø§ÙŠ', 'Ø­Ø¨ÙˆØ´ØªÙŠ', 'Ø§ØµÙ„Ø§', 'Ø§Ù†ÙŠ', 'Ù…ÙˆØ¹Ø¯', 'Ù†ÙˆÙ…ØªÙŠ', 'Ø³Ø§Ø¹Ù‡', 'ÙˆØ§ØµØ­Ù‰', 'Ø³Ø§Ø¹Ù‡', 'ğŸ™ˆ'], 'neg')\n",
      "(['Ø§ØµÙˆØ§Øª', 'Ø¯Ø¹Ø§Ø¡', 'ÙˆØ§Ø¨ØªÙ‡Ø§Ù„Ø§Øª', 'ØªØ¹Ù…', 'Ø§Ø±Ø¬Ø§Ø¡', 'Ø§Ù„Ù…Ø¹Ù…ÙˆØ±Ø©', 'Ø¨Ù…Ù†Ø§Ø³Ø¨Ø©', 'Ø§Ø¬ØªÙ…Ø§Ø¹', 'Ù†Ù‚Ø§Ø¨Ø©', 'Ø§Ù„Ø¹Ø§Ù…Ù„ÙŠÙ†', 'Ù…Ø¹', 'Ø§Ø¯Ø§Ø±Ø©', 'Ø¬Ø§Ù…Ø¹Ø©', 'Ø§Ù„Ø§Ø²Ù‡Ø±', 'Ø¨Ù†ÙŠØ©', 'Ø§Ù„ØºØ§Ø¡', 'Ø§Ù„Ø§Ù…ØªØ­Ø§Ù†Ø§Øªâ€¦'], 'neg')\n",
      "(['ÙŠÙ‚ÙˆÙ„ÙˆÙ†', 'Ø¹Ø§Ø¯ÙŠ', 'ÙŠÙˆÙ…ÙŠÙ†', 'Ùˆ', 'ÙŠØ³ÙƒØªÙˆÙ†', 'ğŸ˜Š'], 'pos')\n",
      "(['ØµÙ„Ø§Ù‡', 'Ø§Ù„ÙØ¬Ø±', 'ÙˆØ§Ø°ÙƒØ§Ø±', 'Ø§Ù„ØµØ¨Ø§Ø­', 'ğŸ’œ'], 'pos')\n",
      "(['ØªØ¨ØºÙˆØ§', 'Ø­ÙƒØ§Ù…', 'ÙˆÙØ§Ø±', 'Ø®Ù„ÙŠÙ„', 'Ø¬Ù„Ø§Ù„', 'ğŸ˜‚'], 'pos')\n",
      "(['Ù…ØªØ¯ÙŠØ´', 'Ù„Ø­Ø¯', 'ÙØ±ØµÙ‡', 'ÙŠØ´ÙˆÙ', 'Ø¶Ø¹ÙÙƒ', 'Ø§Ø¯Ø¹ÙŠ', 'Ø§Ù„Ù‚ÙˆØ©', 'ÙˆØ¥Ù†Øª', 'ÙÙŠ', 'Ø£Ø´Ø¯', 'Ø­Ø§Ø¬ØªÙƒ', 'ğŸ‘Œ'], 'pos')\n",
      "(['Ø§Ù…', 'ÙƒÙ„Ø«ÙˆÙ…', '-', 'Ø§Ù„Ø§Ø·Ù„Ø§Ù„', 'â™¡'], 'pos')\n",
      "(['ğŸ’', 'Ø§Ù„Ù„Ù‡Ù…', 'ğŸ’', 'Ø£Ø¬Ù…Ø¹', 'Ù‚Ù„ÙˆØ¨Ù†Ø§', 'Ø¹Ù„Ù‰', 'Ø­Ø¨ÙƒØŒ', 'ÙˆØ§Ø¬Ù…Ø¹', 'Ø¬ÙˆØ§Ø±Ø­Ù†Ø§', 'Ø¹Ù„Ù‰', 'Ø·Ø§Ø¹ØªÙƒ', 'ÙˆØ§Ø¬Ù…Ø¹', 'Ù†ÙÙˆØ³Ù†Ø§', 'Ø¹Ù„Ù‰', 'Ø®Ø´ÙŠØªÙƒ', 'ÙˆØ§Ø¬Ù…Ø¹', 'Ø£Ø±ÙˆØ§Ø­Ù†Ø§', 'ÙÙŠ', 'Ø¬Ù†ØªÙƒ', 'ÙˆÙ„Ø§', 'ØªØ­Ø±Ù…Ù†Ø§', 'Ø¹ÙÙˆÙƒâ€¦'], 'pos')\n",
      "(['#ÙÙƒ_Ø§Ù„Ø´ÙØ±Ù‡', 'ğŸŒ¹Ø¬Ø¯ÙŠØ¯Ù†Ø§', 'ğŸŒ¹', 'ğŸŒ¹Ù…Ø¬Ù…ÙˆØ¹Ø©', 'Ù…ÙƒÙŠØ§Ø¬ğŸŒ¹', 'ğŸŒ¸Ø¨ÙˆÙƒØ³', 'Ø§Ø±ÙˆØ§Ø¬', 'Ø³Ø§Ø¦Ù„', 'Ø«Ø§Ø¨Øª', 'Ø¯Ø±Ù…ÙƒÙˆÙ„', 'Ù„ÙˆÙ†', 'ğŸŒ¸Ø¸Ù„', 'Ù‡Ø¯Ù‰', 'Ø¨ÙŠÙˆØªÙŠ', 'Ù„ÙˆÙ†', 'Ù…Ø¹', 'Ø§Ø¶Ø§Ø¡Ù‡', 'Ù…Ø¹', 'Ø§Ø­Ù…Ø±', 'Ø®Ø¯â€¦'], 'pos')\n",
      "(['.Ø§Ù„Ù„Ù‡Ù…', 'Ø£Ø¹Ù†ÙŠ', 'Ø¹Ù„Ù‰', 'Ø°ÙƒØ±Ùƒ', 'ÙˆØ´ÙƒØ±Ùƒ', 'ÙˆØ­Ø³Ù†', 'Ø¹Ø¨Ø§Ø¯ØªÙƒ', 'â™¥'], 'pos')\n",
      "(['Ù‡Ù„Ø§', 'ÙˆØ§Ù„Ù„Ù‡', 'Ø¨Ø§Ù„Ù„ÙŠ', 'ÙŠØªØºÙ„Ùˆ', 'ğŸ˜¢', 'Ù†ÙˆØ±Ø±ØªÙŠ', 'Ø§Ù„ØªÙˆÙŠØªØ±', 'ÙƒÙ„Ù„Ù‡', 'ÙŠØ§', 'Ù‚Ù„Ø¨ÙŠ', 'ÙÙ‚Ø¯Ù†Ø§', 'Ø·Ù„ØªÙƒ', '..ğŸ’•ğŸ’›'], 'neg')\n",
      "(['Ø³', 'Ø£ÙÙƒØ±', 'ÙÙŠ', '/', '\\u200bØ¢Ù„Ø£Ù‚Ø±Ø¨', '\\u200bØ¥Ù„Ù‰', 'Ù‚Ù„Ø¨ÙŠ', 'Ù‚Ø¨Ù„', 'Ø¢Ù„Ù…Ù†Ø¢Ù…', 'Ù', 'Ù„Ø¹Ù„Û', 'ÙŠÙƒÙˆÙ†', 'Ø¶ÙŠÙ', 'Ø­Ù„Ù…ÙŠ', 'Ùˆ', 'Ù‚Ø¨Ù„', '\\u200bØ¥ØºÙ…Ø¢Ø¶Ø©', 'Ø¹ÙŠÙ†Ø¢ÙŠ', '.', '.', 'Ø³', '\\u200bØ£Ø±Ø³Ù…', '\\u200bØ¢Ø¨ØªØ³Ø¢Ù…â€¦'], 'pos')\n",
      "(['ÙŠØ§Ø±Ø¨', 'ØªØ®Ù„ÙŠÙ„ÙŠ', 'Ø§Ø®ÙˆØ§ØªÙŠ', 'ÙˆØªØ­ÙØ¸Ù‡Ù…', 'Ù…Ù†', 'ÙƒÙ„', 'Ø´Ø±', 'ğŸ™'], 'pos')\n",
      "(['ÙŠØ§Ø±Ø¨', 'ÙˆØ¥Ù†', 'Ø¶Ø¹ÙØª', 'Ø§Ù„Ø§Ø¬Ø³Ø§Ù…', 'ÙØ£Ù†Øª', 'Ø§Ù„Ù‚ÙˆÙŠ', 'Ø›', 'ÙˆØ¥Ù†', 'Ø¹Ø¬Ø²', 'Ø§Ù„Ø£Ø·Ø¨Ø§Ø¡', 'ÙØ£Ù†Øª', 'Ø§Ù„Ø¹Ø¸ÙŠÙ…', 'Ù„Ø§', 'ÙŠØ¹Ø¬Ø²Ùƒ', 'Ø´ÙŠØ¡', 'ØŒ', 'ÙˆØ¥Ù†', 'Ù‚Ù„', 'Ø§Ù„Ø¯ÙˆØ§Ø¡', 'ÙÙ…Ù†Ùƒ', 'Ø§Ù„Ø´ÙØ§Ø¡', 'ØŒ', 'Ø§Ù„Ù„â€¦'], 'pos')\n",
      "(['Ø§ÙŠ', 'ÙˆØ§Ù„Ù„Ù‡', 'Ù„Ùˆ', 'Ù…Ø§', 'Ø§Ù„Ø·Ø±Ø¯', 'ÙƒØ§Ù†', 'Ø¹Ù„Ù‰', 'Ø§Ù„Ø§Ù‚Ù„', 'ØªØ¹Ø§Ø¯Ù„', 'ğŸ’”'], 'neg')\n",
      "(['Ø§Ù„Ø­ÙˆØ«Ø©', 'Ø§Ùˆ', 'Ù…Ø¬Ù„Ø³', 'Ø§Ù„Ù…Ø·Ù„Ù‚Ø§Øª', 'Ø§Ù„Ø¯Ø§Ø¹Ù…', 'ÙˆØ§Ø­Ø¯', 'Ù‡Ù…', 'Ø´ÙŠØ§Ø·ÙŠÙ†', 'Ø§Ù„Ø¹Ø±Ø¨', '#Ø§Ù„Ø§Ù…Ø§Ø±Ø§Øª', 'ÙÙ„Ø§', 'ØªØ¹Ù„ÙŠÙ‚', 'Ø¨Ø¬Ø¯', '.'], 'pos')\n",
      "(['âœ”ï¸', 'Ø§Ù„Ø­Ù„Ù‚Ø©', 'Ø§Ù„ØªØ§Ø³Ø¹Ø©', 'ÙˆØ§Ù„Ø¹Ø´Ø±ÙˆÙ†', 'Ù…Ù†', 'Ø§Ù„Ø³ÙŠØ±Ø©', 'Ø§Ù„Ù†Ø¨ÙˆÙŠØ©', 'ÙÙŠ', 'ØªØºØ±ÙŠØ¯Ø§Øª', 'ğŸ’¥', 'Ù‡Ø¬Ø±Ø©', 'Ø§Ù„Ù†Ø¨ÙŠ', 'ï·º', 'Ø¥Ù„Ù‰', 'Ø§Ù„Ù…Ø¯ÙŠÙ†Ø©â€¦'], 'neg')\n",
      "(['ØªØ£Ù…Ù…', 'Ù…Ø¹Ø§ÙƒÙŠ', 'Ù…Ù„Ø§Ø¦ÙƒØ©', 'Ø§Ù„Ø±Ø­Ù…Ù†', 'Ù…Ù†', 'Ø¹Ø§Ù„ÙŠ', 'Ø³Ù…Ø§Ù‡', 'ğŸŒ¹'], 'pos')\n",
      "(['Ø¨Ø¨Ù„Ùƒ', 'ÙˆÙ‚ØªÙ‡Ø§', 'ğŸ˜‹'], 'pos')\n",
      "(['Ø´ÙŠØ®Ø©', 'Ø¹Ø±Ø¨', 'Ø¨Ù†Øª', 'Ø§Ù„Ø¹Ø±Ø¨', 'ÙˆØ¨Ù†ÙØ³Ù‡Ø§', 'Ù…Ø¹ØªØ²Ù‡', 'Ø·ÙŠØ¨', 'ÙˆÙ†Ø³Ø¨', 'Ø²ÙŠÙ†', 'ÙˆØ§Ø¯Ø¨', 'ÙˆØ§Ù„Ù„ÙŠ', 'ØªØ¨ÙŠÙ‡', 'ØªØ­ÙˆØ²Ù‡', 'Ù…Ù†', 'Ù…Ø«Ù„Ù‡Ø§', 'Ù…Ù†', 'Ù‚Ø¯Ù‡Ø§', 'ÙˆØ§Ù‚ÙˆÙ‰', 'Ø´Ø¹ÙˆØ±', 'Ø§ØªÙ‡â€¦'], 'pos')\n",
      "(['Ø­Ø¨', 'Ø§Ù„Ø·ÙÙˆÙ„Ø©', 'Ù…Ø§ØªØºÙŠØ±Ù‡', 'Ø§Ù„Ø£ÙŠØ§Ù…', 'ÙˆØ£ØµØ¯Ù‚', 'Ø´Ø¹ÙˆØ±', 'Ø§Ù„Ø­Ø¨', '..', 'Ø­Ø¨', 'Ø§Ù„Ø·ÙÙˆÙ„Ø©', ':('], 'neg')\n",
      "(['4.13ğŸŒŸ~|', 'ØªØ­Ø¯ÙŠØ«', 'Ø­Ø³Ø§Ø¨', 'Ø¨Ø§Ù†Ù‚ØªØ§Ù†', 'Ø§Ù„Ø±Ø³Ù…ÙŠ:', '\"Ø£Ù‡Ù„Ø§', 'ÙƒÙ†Ø¯Ø§', '#spotifyxbts', '\"'], 'pos')\n",
      "(['Ù…Ø­Ø¨ÙƒÙ…', 'ÙŠÙ…Ø±', 'Ø¨Ø£Ø²Ù…Ø©', 'Ù‚Ù„Ø¨ÙŠØ©', 'ğŸ’”', 'Ù„Ø§', 'ØªØ¨Ø®Ù„ÙˆØ§', 'Ø¹Ù„ÙŠ', 'Ø¨Ø¯Ø¹ÙˆØ§ØªÙƒÙ…', 'ÙÙŠ', 'ÙˆÙ‚Øª', 'Ø§Ù„Ø³Ø­Ø±', 'ğŸ™ğŸ»', '#Ù…Ø·Ø±_Ø§Ù„Ø±ÙŠØ§Ø¶', '#Ø¯Ø¹Ø§Ø¡_Ø§Ù„Ù…Ø·Ø±', '#Ø³Ø§Ø¹Ø©_Ø§Ø³ØªØ¬Ø§Ø¨Ø©'], 'neg')\n",
      "(['Ø§Ù„ÙˆØ·Ù†', 'Ø´ÙƒÙ„Ø©', 'ÙƒÙ„Ù‡', 'ØµØ±Ø§Ø±', 'Ø§Ù„Ù„ÙŠÙ„', 'ÙˆØ¬Ø±Ø§Ø¯', 'Ø¨Ø³', 'Ù„Ø§', 'Ø§Ø­Ø¯', 'ÙŠØ³Ù…Ø¹Ù†Ø§', 'ÙˆÙŠÙ‚ÙˆÙ„', 'Ø¹Ø°Ø§Ø¨', 'Ø¨Ø³Ø¨Ø¨', 'Ø­ÙÙ„Ø§Øª', 'Ø§Ù„ØªØ±ÙÙŠØ©', 'ğŸ˜‚'], 'pos')\n",
      "(['Ø­Ø¨ÙŠØ¨Ù†Ø§', 'ÙˆØ§Ø¨ÙˆÙ†Ø§', 'Ù…Ø­Ø¬ÙˆØ¨', 'Ø´Ø±ÙŠÙ', 'Ø­Ø¶ÙˆØ±', 'ÙÙŠ', 'Ø¹Ù†Ø§Ù†', 'Ø³Ù…Ø§Ø¡', 'Ù‡ØªØ§ÙØ§Øª', 'Ø§Ù„ÙˆØ·Ù†', 'ğŸ˜­', 'Ø·ÙÙ„Ùƒ', 'Ø§Ù„Ø®Ù„ÙŠØªÙˆ', 'Ø¯Ø§Ø¨Ùƒ', 'ÙŠØ§Ù…Ø§', 'Ø­ÙŠØ¹Ø¬Ø¨Ùƒ', 'Ø´Ø¨Ø§Ø¨Ùˆ', 'ÙˆØ§Ù„Ø¨Ù†ÙŠØ©', 'Ø§Ù…', 'Ø·Ø±Ø­Ø©', 'ÙƒØ¨Ø±Øªâ€¦'], 'neg')\n",
      "(['Ø§Ù†Øª', 'Ù‚Ù„Øª', 'Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹', 'ÙƒÙ„Ù‡', 'ÙˆØ¨Ø³Ø§Ø·Ø©', 'Ø®Ø§Ù„Øµ', 'Ø£Ø­Ø³Ù†Øª', 'ÙŠØ§Ø¯ÙƒØªÙˆØ±', 'âœ‹'], 'neg')\n",
      "(['ğŸ•Š', 'Ù„ÙŠØ³', 'ÙƒÙ„', 'Ù…Ø§', 'ØªØ¹Ø±ÙÙ‡', 'ÙˆØªØªÙ…Ù†Ø§Ù‡', 'Ù‡Ùˆ', 'Ø§Ù„Ù…Ù†Ø§Ø³Ø¨', 'Ù„Ùƒ', '#ÙØ£Ù‚Ø¯Ø§Ø±', 'Ø§Ù„Ù„Ù‡', 'ÙÙˆÙ‚', 'Ù…Ø³ØªÙˆÙ‰', 'Ø§Ù„ØªØµÙˆØ±Ø§Øª', 'ÙˆØ£Ø¹Ù„Ù‰', 'Ù…Ù†', 'ÙƒÙ„', 'Ø§Ù„Ø£Ù…Ù†ÙŠØ§Øª', 'â¤ï¸', '#Ù‡Ù†Ø§Ùƒ', 'Ø£Ù‚Ø¯Ø§Ø±', 'Ø§Ø±ØªÙ‚Øªâ€¦'], 'pos')\n",
      "(['Ø­Ø¯', 'Ø¨ÙŠØ±ÙˆØ­', 'Ø§Ù„Ù‚Ø±ÙŠØ©', 'Ø§Ù„ÙŠÙˆÙ…', 'ØŸ', 'Ø§Ù„ÙŠ', 'Ø¨ÙŠØ±ÙˆØ­', 'Ù…Ø±', 'Ù…Ù†', 'ØµÙˆØ¨ÙŠ', 'Ø§Ø¨Ø§', 'Ø§Ø±ÙˆØ­', 'ğŸ˜­'], 'neg')\n",
      "(['Ù‚Ù„Ø¨Ùƒ', 'Ø¹Ø§Ù…Ø±', 'Ø¨Ø§Ù„Ø§ÙŠÙ…Ø§Ù†', 'ÙŠØ§', 'Ø§Ø®ØªØ§Ù‡', 'ğŸŒš'], 'pos')\n",
      "(['Ø¨Ù†Ø´ÙˆÙ', 'Ù…ÙŠÙ†', 'Ø§Ù„Ù„ÙŠ', 'ÙŠØ´Ø®Ø¨Ø·', 'Ø§Ù„Ø«Ø§Ù†ÙŠ', 'Ø§Ù„ÙŠÙˆÙ…', 'ğŸ˜'], 'neg')\n",
      "(['Ø·Ø±Ø²Ø§Ù†', 'Ù†ÙØ³Ù‡', 'Ù…', 'Ø¹Ø§Ø´Ø±', 'ÙƒÙ…ÙŠÙ‡', 'Ø§Ù„Ø­ÙŠÙˆØ§Ù†Ø§Øª', 'Ø§Ù„ÙŠ', 'Ø§Ù†Ø§', 'Ø¹Ø§Ø´Ø±ØªÙ‡Ø§', 'ğŸ˜•'], 'neg')\n",
      "(['Ø§Ù‡', 'Ø­Ø¬Ø±', 'ÙˆØ§Ù„Ù„Ù‡', 'ÙŠØ¨Ùˆ', 'Ø¹Ù„ÙŠ', 'ğŸ˜”', 'Ù…Ø´', 'Ø±Ø§Ø¶ÙŠ', 'ÙŠØ·Ø±Ù‰'], 'neg')\n",
      "(['ØµØ­', 'ÙƒØ±Ù', 'ÙˆØªØ¹Ø¨', 'ÙˆÙ‚Ø±Ù', 'ÙˆÙ…Ø§ÙÙŠ', 'Ø²ÙŠ', 'Ø£ÙŠØ§Ù…', 'Ø§Ù„Ù…Ø¯Ø±Ø³Ø©', 'Ù„ÙƒÙ†', 'Ø¨Ø±Ø¶Ùˆ', 'Ù…Ø±Ø­Ù„Ø©', 'Ø§Ù„Ø¬Ø§Ù…Ø¹Ø©', 'Ø­Ø­Ù„ÙˆØ©', 'ÙˆÙ„Ù‡Ø§', 'Ø°ÙƒØ±ÙŠØ§ØªÙ‡Ø§', 'â˜¹'], 'neg')\n",
      "(['Ø£Ù†Ø§', 'Ø§Ù„Ù„ÙŠ', 'Ø³Ù‚ÙØª', 'Ù„Ù„Ù‚Ø±Ø¯', 'ÙˆØ²Ø¹Ù„Øª', 'Ù„Ù…Ø§', 'Ø§ØªÙ†Ø·Ø·ğŸ’', 'ğŸ˜…'], 'pos')\n",
      "(['Ø§Ø¤Ù…Ù†', 'Ø£Ù†', 'Ø§Ù„Ø§ØµØ¯Ù‚Ø§Ø¡', 'ÙŠØ¨Ù‚ÙˆÙ†', 'Ù„Ù„Ø£Ø¨Ø¯', 'ØŒ', 'Ù„Ø°Ø§', 'Ø¬Ù…ÙŠØ¹', 'Ù…Ù†', 'Ø°Ù‡Ø¨ÙˆØ§', 'Ù„Ù…', 'ÙŠÙƒÙˆÙ†ÙˆØ§', 'Ø£ØµØ¯Ù‚Ø§Ø¡', 'ğŸ’›'], 'pos')\n",
      "(['Ù„Ø§', 'ØªØ®ØªØ§Ø±', 'Ø§Ù„Ø´Ø®Øµ', 'Ø§Ù„Ø¬Ù…ÙŠÙ„', 'ØŒ', 'Ø§Ø®ØªØ§Ø±', 'Ø§Ù„Ø´Ø®Øµ', 'Ø§Ù„Ø°ÙŠ', 'ÙŠØ¬Ø¹Ù„', 'ğŸ’', 'Ø­ÙŠØ§ØªÙƒ', 'Ø¬Ù…ÙŠÙ„Ø©', 'ğŸŒ¸'], 'pos')\n",
      "(['Ø¹Ø¸Ù…Ø©', 'Ø¹Ø¸Ù…Ø©', 'Ø¹Ø¸Ù…Ø©', 'ğŸ’–'], 'pos')\n",
      "(['ğŸŒºØ§Ù„Ø³Ù„Ø§Ù…', 'Ø¹Ù„ÙŠÙƒÙ…', 'ÙˆØ±Ø­Ù…Ø©', 'Ø§Ù„Ù„Ù‡', 'ÙˆØ¨Ø±ÙƒØ§ØªÙ‡', 'ğŸŒº', 'ØµØ¨Ø§Ø­', 'Ø§Ù„Ø®ÙŠØ±', 'Ù„Ù„Ø£Ù†Ù‚ÙŠØ§Ø¡ØŒ', 'ÙˆØ£ÙˆÙÙŠØ§Ø¡', 'Ø§Ù„Ø±ÙˆØ­ØŒ', 'Ù„Ù…Ù†', 'Ø¯Ù‡Ø³', 'Ø§Ù„ÙŠØ£Ø³', 'Ø¨Ù‚Ø¯Ù…ÙŠÙ‡', 'ÙˆØ±ÙƒØ¶', 'Ø®Ù„Ù', 'Ø§Ù„Ø£Ù…Ù„ØŒ', 'ÙˆØ§Ù„Ø«Ù‚Ø©â€¦'], 'neg')\n",
      "(['Ø§Ù„Ù…Ø´ÙƒÙ„Ø©', 'Ù…Ø§Ù…Ø§', 'Ø§Ù†Ø³Ø§Ù†Ù‡', 'Ù…Ø­ØªØ±Ù…Ù‡', 'ÙˆØ±Ø¨ÙŠ', 'Ø¹ÙŠØ¨', 'Ù‡Ø§Ù„Ø­Ø±ÙƒØ§Øª', 'ÙˆØ§Ø¹ÙŠÙ‡', 'ÙƒÙ…Ø§Ù†', 'ğŸ’”', 'Ø­Ø³Ø¨ÙŠ', 'Ø§Ù„Ù„Ù‡', 'ÙˆÙ†Ø¹Ù…', 'ÙˆØ§Ù„ÙˆÙƒÙŠÙ„', 'ÙÙŠÙ‡Ø§', 'ğŸ’”'], 'neg')\n",
      "(['Ø§Ù„ÙˆØ§Ù„Ø¯', 'Ø§Ù„Ù„Ù‡', 'ÙŠØ­ÙØ¸Ù‡', 'Ø¨Ø¹Ø±Ø³', 'Ø§Ù„Ø®Ø§Ù„', 'Ø¹Ø¨Ø¯Ø§Ù„Ù„Ù‡', 'Ø§Ù„Ø­Ø¨Ø±Ø§Ù†', 'ÙˆØ§Ù„Ø®Ø§Ù„', 'Ø¹Ø¨Ø¯Ø§Ù„Ø±Ø­Ù…Ù†', 'Ø§Ù„Ø­Ø¨Ø±Ø§Ù†', 'Ø¨Ø§Ù„Ø­ÙØ±', 'Ø§Ù„Ø¨Ø§Ø·Ù†', 'Ø§Ø³Ø£Ù„', 'Ø§Ù„Ù„Ù‡', 'Ø§Ù„ØªÙˆÙÙŠÙ‚', 'Ù„ÙƒÙ…', 'ÙˆØ§Ù†', 'ÙŠØ±Ø²Ù‚Ùƒâ€¦'], 'pos')\n",
      "(['Ø§Ù„Ù‡Ù„Ø§Ù„', 'ÙŠÙ†ØªØµØ±', '..', 'Ù„ÙƒÙ†Ù‡', 'Ø¨Ø¹ÙŠØ¯', 'Ø¬Ø¯Ø§', 'Ø¹Ù†', 'Ù…Ø³ØªÙˆØ§Ù‡', '!', 'Ø¥Ù‡Ø¯Ø§Ø±', 'ØºØ±ÙŠØ¨', '..', 'Ù„ÙØ±Øµ', 'Ø³Ù‡Ù„Ø©', 'Ø¬Ø¯Ø§', '!', 'Ø®Ø·', 'Ø¯ÙØ§Ø¹', 'ÙŠØ¹Ø§Ù†ÙŠ', 'ÙƒØ«ÙŠØ±Ø§', '!', 'ÙƒÙ†Ùˆ', '..', 'Ø¥Ù…Ùƒâ€¦'], 'pos')\n",
      "(['Ù…Ø¯Ø±ÙŠ', 'Ù…Ùˆ', 'Ø¹Ø§Ø¯ØªÙŠ', 'Ø§ØµÙ„Ø§', 'ğŸ˜­'], 'neg')\n",
      "(['Ù‡Ø§', 'Ø¯Ø¬Ù„Ù‡ğŸ˜’', 'Ø´Ù†Ù‡Ùˆ', 'Ø§Ù„ØµØ§Ø±', 'Ø­ÙŠÙ„', 'Ø§Ø®ØªÙ„ÙØªÙŠ', 'ğŸ˜¥', 'Ù…Ùˆ', 'Ø§Ù†ØªÙŠ', 'Ø§Ù…', 'Ø§Ù„Ø®ÙŠØ±', 'Ù…Ø¹Ù‚ÙˆÙ„Ù‡', 'Ø¬Ø¹ØªÙŠğŸ¤š', '.', '.', '#ØºØ±Ù‚_Ø§Ù„Ø¹Ø¨Ø§Ø±Ù‡_ÙÙŠ_Ø§Ù„Ù…ÙˆØµÙ„', '#Ø¹Ø·ÙˆØ±Ù‡ğŸ’•', '#Ø´ÙˆØ´ÙˆğŸ’•â€¦'], 'neg')\n",
      "(['Ù…Ø´', 'Ø¹Ø§Ø§Ø±Ù', 'ğŸ˜‚'], 'pos')\n",
      "(['Ù…Ùˆ', 'ÙØ±Ø­', 'ØµØ¯Ù‚ÙŠÙ†ÙŠ', 'Ø§Ù„Ø§', 'Ø¹Ø´Ø§Ù†', 'Ù†Ø°Ù„', 'Ø§Ù…', 'Ø§Ù…Ù‡Ù…', 'ÙÙŠ', 'Ø­Ø±ÙƒØªÙ‡Ù…', 'Ø°ÙŠ', 'ğŸ¤£'], 'pos')\n",
      "(['Ø¨Ù…Ù†Ø§Ø³Ø¨Ø©', 'ÙÙˆØ²', 'Ø§Ù„Ù‡Ù„Ø§Ù„', '..', 'ğŸ’™', 'Ø³Ø­Ø¨', 'Ø¹Ù„Ù‰', 'Ø¢ÙŠÙÙˆÙ†', 'XRğŸ“±', 'Ø±ØªÙˆÙŠØª', 'ÙˆØªØ§Ø¨Ø¹', '-', 'Ø§Ù„Ø³Ø­Ø¨', 'Ø¨Ø¹Ø¯', 'Ø³Ø§Ø¹Ø©', 'Ù…ÙˆØ«Ù‚', 'Ø¨Ø§Ù„ÙØ¯ÙŠÙˆ', 'ğŸ’ª'], 'pos')\n",
      "(['Ø§Ø²Ø§Ù‰', 'ÙƒÙ†ØªÙˆ', 'Ù‚Ø±ÙŠØ¨ÙŠÙ†', 'Ø§ÙˆÙ‰', 'Ù…Ù†Ù†Ø§', 'ÙˆØ¹Ø§Ø±ÙÙŠÙ†Ø§', 'Ø§ÙˆÙ‰', 'ÙƒØ¯Ù‡', 'ÙˆØ¨Ø±Ø¶Ùˆ', 'Ø¹Ø§Ù…Ù„ÙŠÙ†', 'ØªØ¬Ø±Ø­Ùˆ', 'ÙÙŠÙ†Ø§', 'Ø§Ø²Ø§Ù‰', 'Ø¨Ù†Ø­Ø¨ÙƒÙ…', 'Ø·ÙˆÙ„', 'Ø§Ù„ÙˆÙ‚Øª', 'ÙˆØ§Ù†ØªÙˆ', 'ØªØ£Ø°ÙˆÙ†Ø§', 'Ø·ÙˆÙ„', 'Ø§Ù„ÙˆÙ‚Øª', 'ğŸ’”'], 'neg')\n",
      "(['ğŸ“¸', 'Ø§Ù„Ø¢Ù†', 'Ø£Ø¯Ø§Ø¡', 'Ø¬ÙŠÙ†ÙŠ', 'Ù„Ø³ÙˆÙ„Ùˆ', 'ØŒ', 'Ø±ÙˆØ²ÙŠ', 'Ù‚Ø§Ù…Øª', 'Ø¨ØªÙ‚Ø¯ÙŠÙ…', 'Ø¬ÙŠÙ†ÙŠ', 'Ù„Ù„Ø­Ø¶ÙˆØ±', 'Ø¨Ø·Ø±ÙŠÙ‚Ø©', 'Ù„Ø·ÙŠÙØ©', 'ğŸ’—', '-', 'Ø§Ø¨Ø±ÙŠÙ„', 'ØŒ'], 'pos')\n",
      "(['ÙƒÙ„', 'Ù‡Ø§Ù„Ø¹Ø§Ù„Ù…', 'ØªØ±ÙƒÙ†Ø§Ù‡Ù…', 'Ø¹Ø´Ø§Ù†Ùƒ', 'ÙˆÙƒÙ„', 'Ù‡Ø§Ù„Ø¯Ù†ÙŠØ§', 'Ù†Ø³ÙŠÙ†Ø§Ù‡Ø§', 'Ø³ÙˆØ§Ùƒâ™¥ï¸'], 'pos')\n",
      "(['ÙˆØ§ÙŠØ§Ù…Ùƒ', 'Ø¨Ø§Ù„Ø®ÙŠØ±', 'Ø§Ù†', 'Ø´Ø§Ø¡', 'Ø§Ù„Ù„Ù‡', 'ğŸŒº'], 'pos')\n",
      "(['Ù…Ø§', 'Ù„Ø§Ù…Ø³', 'Ø§Ù„Ù‚Ø±Ø¢Ù†', 'Ù‚Ù„Ø¨Ø§', 'Ø¶ÙŠÙ‚Ø§', 'Ø¥Ù„Ø§', 'Ø§ØªØ³Ø¹', '..', 'ğŸ’™'], 'pos')\n",
      "(['Ø¹Ù„Ù‚ÙˆÙ†ÙŠ', 'Ø¨', 'Ø§Ù„Ù…Ø±Ø§Ø³ÙŠÙ„', 'ÙˆØ§Ø¨ÙŠØ§Øª', 'Ø§Ù„Ù‚ØµÙŠØ¯', 'ÙˆØ§Ø³ØªØ¨Ø§Ø­Ùˆ', 'Ø³ÙƒØ©', 'Ø§Ù„Ø¨Ø¹Ø¯', 'Ù‚Ø¯Ù‡Ù…', 'Ø¹Ø§ÙŠÙÙŠÙ†', 'ğŸ’”'], 'neg')\n",
      "(['Ø³Ø§Ø±Ù‚Ù‡Ø§', 'Ù…Ù†', 'Ø§Ø­Ù…Ø¯', 'Ø§Ù„Ø³Ù‚Ø§'], 'neg')\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "sample_size = 100\n",
    "print('{} random tweets .... '.format(sample_size))\n",
    "for s in random.sample(train_data, sample_size):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data info\n",
      "test data size 47000\n",
      "# of positive 5970\n",
      "# of negative 5781\n"
     ]
    }
   ],
   "source": [
    "print('test data info')\n",
    "test_data = pos_test_data + neg_test_data\n",
    "print('test data size', len(train_data))\n",
    "print('# of positive', len(pos_test_data))\n",
    "print('# of negative', len(neg_test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merging all features ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merging all features ... \n",
      "len(all_features): 770508\n"
     ]
    }
   ],
   "source": [
    "print('merging all features ... ')\n",
    "all_features = pos_train_feat + neg_train_feat + \\\n",
    "               pos_test_feat + pos_test_feat\n",
    "print('len(all_features):', len(all_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 sample features ...\n",
      "['Ù„Ù†', 'ÙˆØ§Ù†Øª', 'Ù‡Ø§Ù†ÙŠ', 'Ù‚ÙŠÙ…Ø©', 'Ù„Ù†Ø§', 'ğŸŒ¹', 'Ù…Ø§Ù„Ù‡', 'Ø§Ù„Ù†Ø§Ø³', 'Ùˆ', 'ÙƒÙ„', 'Ø§Ù„Ø¯ÙˆØ±ÙŠ', 'Ø®Ù„Ùƒ', 'Ø§Ù„Ø¹Ø§Ù„Ù…', 'Ø§Ù„Ø²Ù„Ù‡', 'Ø¬Ø¯Ù‡Ø§', 'Ø§Ø®Ø°ØªÙ†ÙŠ', 'ğŸ”´Ø§Ø±Ø³Ù„ÙŠ', 'Ù…Ø«Ù„', 'Ø«Ø§Ù„Ø«', '-', 'Ù„ÙŠÙ‡', 'Ø±Ù‚ÙŠØªØ§Ù†', ':-', 'Ù…Ø§Ù„ÙŠ', 'ÙƒÙ„', 'Ø§Ù„ÙˆØ­ÙŠØ¯', 'Ø¥Ù†Ù…Ø§', 'Ø§Ù„Ø­Ø§Ø¯ÙŠØ©', 'Ø®Ù„ÙŠÙ„', 'Ø§Ù„Ù…ØªØ¨Ø¹Ø«Ø±', 'Ù„Ù‡Ø§', 'Ø§Ø³Ø±Ø¹', 'ÙƒØ§Ù†', 'Ø¨Ù…ÙØ±Ø¯ÙŠ', '/0', 'Ù…Ù†Ù‡Ø§', 'â™ª', 'Ø§Ù„ØªØ§Ù†ÙŠ', 'Ø¨Ø¹Ø¶', 'Ø§Ù„ÙƒØªØ§Ø¨Ø©', '!!', 'Ø§Ù„Ø§ÙˆÙ„', 'ÙŠ', '.', 'Ù„ÙŠØ¨ÙŠØ§:', 'Ø§Ù„Ø±Ø¬ÙÙ‡', 'Ø³Ø§Ø¹Ø©', 'Ù„ØºØ§ÙŠØªÙ‡', 'ğŸ’™', 'Ø¹Ù„ÙŠÙ‡Ø§', 'ÙˆØ§Ù„Ù‚Ø±ÙŠØ¨', 'ğŸ”¨', 'ØªÙˆØ¬ÙŠÙ‡', 'ØªØ­Ø§ÙˆÙ„', 'ÙˆÙ…Ù†', 'Ø¨Ø§Ù„ØµØ­Ø©', 'Ø¯ÙˆÙ„', 'Ù„Ø§ÙŠÙ…ÙˆØªÙˆÙ†', 'â¤', 'â”…â”â€', 'Ø§Ù„Ù…Ø±ØªØ§Ø­', 'Ø¨Ø·Ø±ÙŠÙ‚Ø©', 'Ø§Ù„Ø³Ù„Ø§Ù…Ø©!', 'Ø­Ù„ÙŠØ¨', 'Ù†Ø¨Ø¶â€¦', 'ÙŠØ£ØªÙŠ', 'Ø§Ù†Ø§', 'Ø§Ù„Ù„â€¦', 'ÙŠÙ†ØªØµØ±', 'ÙØ±ÙŠÙ‚ÙŠ', 'ğŸŒ³', 'Ø´ÙƒØ±Ø§', '#Ø³Ø§Ø¹Ù‡_Ø§Ø³ØªØ¬Ø§Ø¨Ù‡', 'Ù‚Ù„Ø¨Ùƒ', 'ÙˆÙ…ÙˆØ¹Ø¯Ù†Ø§', 'Ø¥Ù†', 'Ù„Ø£Ù…Ø±', 'Ù…Ø­Ù…Ø¯', 'ğŸ’”', 'Ø±ÙˆØ¹Ù‡', 'Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©', 'Ø·Ø§Ù‚ØªÙŠ', 'ÙˆØ£Ø¨ØªØ¹Ø¯', 'Ø´Ù‡Ø¯Ø§Ø¦Ù†â€¦', 'Ø£ØµØ¨Ø­', 'ÙŠØªØºÙŠØ±ÙˆÙ†', 'Ø§Ù†Ø§', 'ğŸ’š', 'Ø«Ø§Ù†ÙŠØ©ØŒ', 'â €â”ˆâ”‰â”â—ˆâ™”â™šâ™”â—ˆâ”â”…â”„', 'Ã—', 'Ù…Ø³ØªÙ…Ø±', 'Ù…Ù†', 'ÙƒÙ†ØªÙ…', 'ØµØ¨Ø§Ø­', 'ğŸ˜', 'ÙƒÙ„Ù…Ø©', 'Ø§Ù„Ø®ÙŠØ±', 'ÙŠØ§Ø²Ø¹Ù…Ø§Ø¡', 'Ù‡Ø°ÙˆÙ„']\n"
     ]
    }
   ],
   "source": [
    "print('{} sample features ...'.format(sample_size))\n",
    "print(random.sample(all_features, sample_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compute frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features_count = {}\n",
    "for w in all_features:\n",
    "    all_features_count[w] = all_features_count.get(w, 0) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample frequencies\n",
      "[('Ù‡Ø°ÙˆÙ„ÙŠ', 5), ('ØªØºÙ†Ù†Ø§', 1), ('ğŸŒ´ÙˆØ¨Ø§Ø±Ùƒ', 1), ('ï¸âƒ£ÙŠØ¹Ø·Ù‰..ØŸ!!', 1), ('Ù‡Ù†Ø§Ù„Ùƒ', 9), ('Ø§Ù„Ø¶Ø±ÙˆØ±ÙŠ', 3), ('Ø£Ù†Ø¨Ø¶Ù‡Ø§', 2), ('Ø§ØªÙƒØ±Ù…Øª', 1), ('Ù…Ø±ØªÙŠÙ†ØŒ', 1), ('â€', 154), ('Ù„Ù„ÙˆØ¶Ø¹', 1), ('ØºØ§Ø¨Ù‡', 2), ('ï»³ïº®', 1), ('ğŸ™ƒğŸ™„', 1), ('Ø£Ø­ÙŠØ§Ø¡..!', 1), ('ÙˆÙ„Ø§Ø®Ù„ØµÙˆÙˆ', 2), ('Ø§Ù„Ø¯ÙˆØ±Ø¹Ù„Ù‰', 1), ('#ÙŠØ§Ø¨Ùˆ_Ø¯Ø§Ù„ÙŠÙ†â¤ï¸', 1), ('Ø³Ø¨Ù‚Ù‡', 1), ('Ø£Ù‡Ù‡Ø®', 1), ('ÙˆØ§Ù„Ù‚Ø¯ÙŠÙ…', 1), ('Ø¨ØªØ³Ù‚Ø·', 1), ('Ø¥Ù†Ø¹ÙˆØ§Ø¬Ù‡', 2), ('ÙˆØ²ÙˆØ¯ÙˆÙ‡Ø§', 1), ('Ø£ÙˆÙƒ', 1), ('Ù…Ø§ØªØµØ­Ù‰', 2), ('ğŸ‘±ğŸ»\\u200dâ™€ï¸:', 3), ('Ø´Ù‡Ø±Ø§', 2), ('ğŸ˜ğŸ™Š', 1), ('ÙˆÙ†Ø³Ù‰', 1)]\n",
      "freq of word ÙÙŠ is 9550\n",
      "freq of word ÙÙ‰ is 220\n",
      "freq of word Ù…Ù† is 12655\n"
     ]
    }
   ],
   "source": [
    "print('sample frequencies')\n",
    "print(random.sample(list(all_features_count.items()), 30))\n",
    "word = 'ÙÙŠ'\n",
    "print('freq of word {} is {}'.format(word, all_features_count.get(word, 0)))\n",
    "word = 'ÙÙ‰'\n",
    "print('freq of word {} is {}'.format(word, all_features_count.get(word, 0)))\n",
    "word = 'Ù…Ù†'\n",
    "print('freq of word {} is {}'.format(word, all_features_count.get(word, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training data: 47000\n",
      "min document frequency: 47\n",
      "max document frequency: 46060\n"
     ]
    }
   ],
   "source": [
    "print('size of training data:',  len(train_data))\n",
    "min_df = int(0.001 * len(train_data))\n",
    "max_df = int(0.98 * len(train_data))\n",
    "print('min document frequency:', min_df)\n",
    "print('max document frequency:', max_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting Features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1961 are kept out of 770508\n"
     ]
    }
   ],
   "source": [
    "# remove features that have frequency below/above the threshold\n",
    "my_features = set([word for word, freq in all_features_count.items() if  max_df > freq > min_df ])\n",
    "print(len(my_features), 'are kept out of', len(all_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample of selected features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 sample of selected features:\n",
      "['Ø§Ù„ÙŠÙˆØªÙŠÙˆØ¨', 'Ù†ÙˆØ±Ø§', '[', 'Ù„ÙŠÙ„Ù‡', 'Ø§Ù„Ø¬Ø§Ù‡Ù„', 'ğŸ˜·', 'Ù†Ø³Ø£Ù„Ùƒ', 'ğŸ™„', 'ØªÙƒÙˆÙ†', 'Ø¨ØµÙˆØª', 'Ø§Ù„Ø¯ÙˆÙ„ÙŠØ©', 'ÙˆÙ‡ÙŠ', 'Ø¨Ø³ØªØ­Ù‚', 'X', 'Ø§Ù„Ù‚Ù…Ø±', 'Ø¨Ø§Ù„Ù‡Ø¨ÙˆØ·.', 'Ø£Ø®Ø°', 'Ø§Ø¯Ø±ÙŠ', 'Ø´ÙˆÙŠ', 'ÙˆØ£Ù†ØªÙ…', 'Ø£Ù†Ø§', 'ğŸŒŸ', 'Ø­Ø±ÙÙŠØ§', 'ÙˆØ´ÙˆÙ„ÙˆÙ‡', 'Ø§ØºÙ†ÙŠØ©', 'ÙˆØ­Ø±ÙˆÙ', 'Ø§Ù†ØªØ¸Ø±Ùƒ', 'Ø§Ù„Ø¯Ù‡Ø±', 'Ù„Ù„Ø­ÙŠÙ†', 'Ù†Ø¹Ù…', 'Ø§Ù„Ø±Ø³ÙˆÙ„', 'ğŸ‘Œ', 'Luv', 'Ù„ÙƒÙ†Ù‡', 'Ø­ÙŠÙ†Ù…Ø§', 'Ø¨Ø³Ù…', 'Ø§Ù„Ø­ÙŠ', 'Ø§Ù„ØµØ¯Ø§Ø±Ø©', 'ÙˆØµÙ„Øª', 'Ù…Ø¨Ø±ÙˆÙƒ', 'Ø¨Ø§Ù„ÙŠÙˆÙ…', 'ÙˆÙŠØ§Ùƒ', 'ÙˆØ§Ù„ÙŠÙˆÙ…', 'ğŸ˜€', 'ÙˆØ¨Ø¹Ø¯ÙŠÙ†', 'Ø§Ù„ÙÙŠÙØ§', 'Ø´Ù‡ÙˆØ±', 'ÙŠÙ†Ø§Ù…', 'Ø¨Ø­Ø§Ø¬Ø©', 'â €â €', 'Ø§Ù„Ø¨Ø´ÙŠØ±', 'ÙÙŠÙ†', 'Ø¥Ù†Øª', 'Ø³Ù†ÙˆØ§Øª', 'Ø­ÙŠØ§ØªÙƒ', 'ØªÙˆÙ‚Ø¹Ùƒ', 'Ø¨ÙŠÙ†Ùƒ', 'Ø§Ø´Ù‡Ø±', 'Ø£ÙŠÙ†', 'Ø¹Ø´Ø§Ù†', 'Ø¨Ø¯ÙŠ', 'Ù…Ù†Ù‡Ø§', 'Ù‡ÙƒØ°Ø§', 'ÙˆØ¬Ù‡', 'Ø§Ù„Ø¹Ø§Ù„Ù…', 'Ø§Ù„Ø§ÙˆÙ„', 'ÙŠØ­Ø¯Ø«', 'Ø§Ù„ÙØªØ±Ø©', 'ÙˆØ±Ø¨ÙŠ', 'Ù…Ù„Ú¯ÙŠØ©â™›', 'Ø³Ø¤Ø§Ù„', 'Ù…ÙƒØ§Ù†', 'ØµØ¨Ø­', 'Ø§Ù„Ù…Ø³ÙŠØ§Ø±', 'Ø§Ù„Ø¨Ø¹Ø¶', 'ÙˆØªÙ„ÙØ¸', 'Ø£Ù…ÙŠ', 'Ø¹Ø´Ù‚', 'Ù†ØªÙŠØ¬Ø©', 'Ø§Ù„ØªØºØ±ÙŠØ¯Ù‡', 'Ø£Ø´ÙŠØ§Ø¡', 'Ø§Ù†Øª', 'Ø§Ù…Ø§', 'Ø§Ù„Ø¯ÙˆØ±ÙŠ', 'â‡£', 'ğŸ˜‡', 'Ù…Ø«Ù„Ø§', 'Ø´ÙŠ', 'Ø§Ù„Ø­Ø¯ÙŠØ«', 'Ù†ÙØ³Ù‡', 'Ø°Ù…ØªÙƒ', 'Ø£Ø­Ø³Ù†', 'Ø§Ø¨Ø¯', 'Ø®Ø¨Ø±', 'Ø§ÙƒØ«Ø±', 'Ø¹Ø±ÙØª', 'Ø§Ù„Ø­Ø²Ù†', 'Ø¯Ù‚ÙŠÙ‚Ø©', 'Ù†Ø¨ÙŠÙ†Ø§', 'Ø±Ø¯']\n"
     ]
    }
   ],
   "source": [
    "print('{} sample of selected features:'.format(sample_size))\n",
    "print(random.sample(list(my_features), sample_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generating features for training documents ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sets = [(document_features(d, my_features), c) for (d, c) in train_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training is done\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(feature_sets)\n",
    "print('training is done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most informative features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "               has(Ù…ÙˆØ«Ù‚) = True              pos : neg    =    238.5 : 1.0\n",
      "                  has(ğŸ˜­) = True              neg : pos    =    202.0 : 1.0\n",
      "                  has(ğŸ˜¢) = True              neg : pos    =    171.3 : 1.0\n",
      "            has(Ø§Ù„Ù…Ø³ÙŠØ§Ø±) = True              pos : neg    =    170.1 : 1.0\n",
      "              has(ÙˆØµÙ„ÙˆØ§) = True              pos : neg    =    166.9 : 1.0\n",
      "                  has(ğŸ˜³) = True              neg : pos    =    164.2 : 1.0\n",
      "             has(Ø§Ù„Ø´Ø±ÙˆØ·) = True              pos : neg    =    151.4 : 1.0\n",
      "              has(ÙˆØªØ§Ø¨Ø¹) = True              pos : neg    =    143.9 : 1.0\n",
      "               has(Ø¨Ø¨ÙƒÙŠ) = True              neg : pos    =    143.6 : 1.0\n",
      "                  has(ğŸ¥€) = True              neg : pos    =    132.4 : 1.0\n",
      "              has(Ø§Ù„Ø³Ø­Ø¨) = True              pos : neg    =    118.4 : 1.0\n",
      "                  has(ğŸ’) = True              pos : neg    =    116.5 : 1.0\n",
      "             has(Ø§Ù„Ø¹Ø±ÙˆØ³) = True              neg : pos    =    113.3 : 1.0\n",
      "             has(ÙŠØ´Ø¬Ø¹ÙˆÙ†) = True              pos : neg    =    100.5 : 1.0\n",
      "               has(Ø±ÙƒØ¨Øª) = True              neg : pos    =    100.2 : 1.0\n",
      "                has(Ø¨Ø¶Ù„) = True              neg : pos    =     98.8 : 1.0\n",
      "               has(Ù†Ø´Ø¨Ø©) = True              neg : pos    =     97.4 : 1.0\n",
      "                  has(ğŸ˜) = True              neg : pos    =     97.3 : 1.0\n",
      "                  has(ğŸ™ˆ) = True              neg : pos    =     97.2 : 1.0\n",
      "             has(ÙˆÙƒØ£Ù†Ù‡Ù…) = True              neg : pos    =     94.7 : 1.0\n",
      "                  has(ğŸ˜) = True              neg : pos    =     91.9 : 1.0\n",
      "                  has(ğŸ˜”) = True              neg : pos    =     91.3 : 1.0\n",
      "                 has(:() = True              neg : pos    =     87.5 : 1.0\n",
      "                  has(ğŸ˜·) = True              neg : pos    =     85.0 : 1.0\n",
      "              has(Ø´Ø¯ÙŠØ¯Ø©) = True              neg : pos    =     82.4 : 1.0\n",
      "            has(Ø§Ù„Ø²Ø±Ù‚Ø§Ø¡) = True              pos : neg    =     82.3 : 1.0\n",
      "              has(ØªÙˆØ¬ÙŠÙ‡) = True              neg : pos    =     79.5 : 1.0\n",
      "              has(Ø³ÙˆØ¯Ø§Ù†) = True              neg : pos    =     78.8 : 1.0\n",
      "                 has(ÙØ¶) = True              neg : pos    =     78.1 : 1.0\n",
      "            has(Ø¨Ù…Ù†Ø§Ø³Ø¨Ø©) = True              pos : neg    =     74.9 : 1.0\n",
      "                  has(ğŸ˜±) = True              neg : pos    =     71.3 : 1.0\n",
      "               has(Ø§Ù†Ø¸Ø±) = True              pos : neg    =     70.7 : 1.0\n",
      "                  has(ğŸ¤”) = True              neg : pos    =     67.5 : 1.0\n",
      "              has(Ù‚ÙŠÙ…ØªÙ‡) = True              pos : neg    =     67.5 : 1.0\n",
      "                  has(ğŸ˜’) = True              neg : pos    =     66.7 : 1.0\n",
      "                  has(ğŸ˜•) = True              neg : pos    =     66.0 : 1.0\n",
      "            has(Ø§Ù„Ø§ÙŠÙÙˆÙ†) = True              pos : neg    =     62.9 : 1.0\n",
      "               has(Ù…Ø¨Ù„Øº) = True              pos : neg    =     62.1 : 1.0\n",
      "           has(Ø§Ù„Ù…Ø³Ø§Ø¨Ù‚Ø©) = True              pos : neg    =     61.6 : 1.0\n",
      "                  has(ğŸ’—) = True              pos : neg    =     61.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generating features for test documents ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = [(document_features(d, my_features), c) for (d, c) in test_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classify test instances "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_sets = collections.defaultdict(set)\n",
    "test_sets = collections.defaultdict(set)\n",
    "\n",
    "for i, (feats, label) in enumerate(test_features):\n",
    "    ref_sets[label].add(i)\n",
    "    observed = classifier.classify(feats)\n",
    "    test_sets[observed].add(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8913283975831844\n",
      "pos precision:  0.9198425478618716\n",
      "pos recall: 0.8611390284757119\n",
      "neg precision:  0.8654657578708211\n",
      "neg recall: 0.9225047569624633\n",
      "positive f-score: 0.8895233151656718\n",
      "negative f-score: 0.8930754416813196\n"
     ]
    }
   ],
   "source": [
    "print('accuracy: ', nltk.classify.accuracy(classifier, test_features))\n",
    "print('pos precision: ', precision(ref_sets['pos'], test_sets['pos']))\n",
    "print('pos recall:', recall(ref_sets['pos'], test_sets['pos']))\n",
    "print('neg precision: ', precision(ref_sets['neg'], test_sets['neg']))\n",
    "print('neg recall:', recall(ref_sets['neg'], test_sets['neg']))\n",
    "print('positive f-score:', f_measure(ref_sets['pos'], test_sets['pos']))\n",
    "print('negative f-score:', f_measure(ref_sets['neg'], test_sets['neg']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
